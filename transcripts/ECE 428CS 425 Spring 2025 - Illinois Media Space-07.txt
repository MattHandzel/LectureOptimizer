Thank you.
All right everyone, let us get started.
Ok, so just a quick reminder like a homework 1 is due on Friday and homework 2 will also
be released on the same day.
Also I have posted some notes about midterm 1 on campus wire, so please make sure you take
a look at that post.
So, in particular it is your midterm your first midterm is the time range March 4th to March
6th.
So, you can pick like any available slots on CBTF in this time range for your midterm and
the reservation will start tomorrow.
So, like tomorrow onwards you could like reserve a slot on on prairie test.
And your syllabus will include everything up to and including global states.
So, basically like up to like what the portion covered as part of homework 1.
And yeah.
So, Balticat onwards is not part of the midterm and syllabus.
And just a quick note that CBTF does not allow cheat sheets.
I would have liked you all to have the option of making your own cheat sheets.
But CBTF does not support that option.
So, we will provide an abridged version of the slides as a reference cheat sheet during
the exam.
And this cheat sheet has been linked to my campus via post as well for prior reference.
And as also in my post, make sure that you study well for the exam and you don't just
rely on the cheat sheet.
It's something I discussed during the first lecture itself.
If like the cheat sheet is just for like you know quick reference or maybe like some formula.
Like just to kind of avoid memorizing stiff stuff.
Like but you need to make sure that you know all the concepts well.
And they cannot just like you know you basically it's a 50 minute long exam.
So, you won't have time to like you know just go and refer to the cheat sheet for each
and every little thing.
It's a pretty long.
The cheat sheet just basically covers all the slides.
So, if you rely on referring too much to the cheat sheet during the exam you may not have
enough time for that.
So, make sure you study well.
You know the concepts well.
Also the exam questions will not just be like direct application of the formula that
is written in the cheat sheet.
It will require you to have a good understanding of the concept.
So, in the past I've seen that like, something I was also mentioning last time.
So like last year actually the average score on my exams for similar difficulty level were
lower than what they were the year before.
So, the year before I didn't have any cheat sheet and it was a few bit lower last time.
So, I felt that you know people might have fallen into the trap of relying too much on the cheat
sheet.
So, please don't fall into that trap.
CBTF will provide scratch papers and calculators and please make sure you check out all of the
CBTF rules.
They have been linked on my campus via post.
Any questions?
Yeah.
So, homework one might not be graded before the exam, but we will release the solution
once we're done with the deadline.
Yeah.
Any other questions?
If you're working on MP0 grading, it may not be done by today as promised by Marcel, but
it will be done soon.
I mean, if you know your MP0 works, it works, right?
You don't need to have the MP0 graded to start working on MP1 if that's what you're worried
about.
Yeah, yeah, yeah.
I think there was a campus via post saying that there is some, might have created some
mental dependency between MP0 and MP1, but if you know your MP0 works, you're able to
kind of see all the logs in the centralized logger, you know it works, right?
So, yeah, you should be able to start working on MP1 irrespective of when you finish grading
MP0.
Grading may take some time because we'll be running your code on our cluster and making sure
that everything works.
So, yeah, it's not an instantaneous activity.
Okay.
Did my microphone stop working?
You can hear me at the back, right?
Yeah.
Okay, I have a question.
No, I announced this in the very first class.
There won't be any practice exam because, again, people fall into the trap of assuming
that whatever practice questions I've given are a template for the actual questions which
won't be the case and homeworks are there for practice.
The homework one, I am making sure that all of the materials covered as part of homework
one are the ones that you've been quizzed on.
I'm not including multicast in the midterm exam for that reason.
Yeah.
What part of homework two will be on the exam?
Nothing, nothing.
This is just what I said, right?
Multicast onwards is not in the, actually, okay, you don't know that, okay, homework two,
okay, global states has been covered as part of homework one.
Homework two will be multicast onwards.
Multicast onwards will not be part of your exam, okay?
Yeah.
Yeah, so Feb 12 is basically was the last, Feb 12 was when I finished the discussion of
global states.
Yeah.
That's, yeah.
Before that, yeah.
Yeah.
Refer to my campus via post.
Yeah.
Okay.
All right.
Any other questions?
Okay.
All right.
So let's move on with our main technical agenda for today.
So we are going to continue discussion of multicast.
You can hear me at the back, right, because I felt that my microphone just stopped working,
but as long as you all can hear me, it's good.
Okay.
So yeah, we are going to continue discussion of multicast and then if time we are going
to start mutual exclusion.
Okay.
So just a quick recap of multicast.
So we discussed how it's a useful communication mode in the systems.
We use multicast for writing objects across replica servers, for group messaging, even as
part of some of the algorithms we have discussed like centralized heartbeats and sending markers
with Chandy Lambert and so on.
So the very basic multicast protocol just simply involves the sending process, unicasting the
message to each process in the multicast group, but this does not guarantee consistent message
delivery.
Similarly, if the sender fails you could it could be it could happen that subset of the
processes receive the message and another subset does not.
So, based on that we define the notion of a reliable multicast which is defined by three
properties integrity, validity and agreement.
And the key thing here is that if some correct process multicast the message M, then all correct
processes deliver M exactly once.
And the way to achieve that is that when a process receives the message M for the first
time, it remulticasts again to other processes in the group.
Okay.
So, these were like sort of the basic multicast and reliable multicast for like two flavors
with different levels of consistency.
But then we also have different ordering flavors, pipe order, causal order, total order.
Any questions on that?
Okay.
So, we are already discussed how to implement a pipe, how to implement PIFO.

So, the basic idea is that each process maintains a counter of how many multicast it has issued
and receiving process make sure that whatever multicast it receives from some other process.
PIFO is indeed the next multicast expecting from PIFO.
So, that's where that is basically in sequence numbers.
Then we started discussing total order multicast and the idea is similar except that instead
of each sender individually maintaining a counter of the multicast it has issued.
We maintain a global sequence counter across all messages that are issued in the system.
And one way to do that is by using a centralized sequencer that creates a total order across all of the multicast.
So, all all all processes when they show multicast they also send the message to the sequencer
and the sequencer will assign a sequence number to that multicast.
And then each process ensures that they are delivering the messages in the order of the sequence number.
So, one issue with a centralized sequencer based approach is a centralized sequencer would fail
and then your system would have to have some kind of a failure detection mechanism to detect that
elect a new sequencer and that might like at times complicate things.
So, we often also think about a decentralized mechanism and that's where we almost ended.
So, we had just touched upon this ISIS mechanism.
So, let me let me dive into that in more details.
So, what we discussed was basically how this ISIS algorithm involves three steps.
So, any time a process issues a multicast it will basically send send that message to all
of the other processes including itself.
And then each process will propose a sequence number for that message.
And this this this this proposed sequence number will basically send it back to the sender.
And the sender will pick the highest of these proposed sequence numbers as the final sequence
number.

And the key lies in like basically the logic used in proposing and proposing the sequence number
and picking that final sequence number.
We all like we can refer to these sequence numbers also as priority because we are maintaining
a priority queue of messages based on these numbers.
So, the first step is send a multicast the message to everyone and the receiving processes
reply with the proposed priority or sequence number.
So, this must be larger than all observed agreed upon priority values and it's larger than
any previously proposed priority value.
And then the message is stored in a priority queue which is ordered by the priority.
The priority here could be the proposed or the agreed upon priority and the message is marked
as undeliverable.
So, then the sender chooses an agreed upon chooses an agreed priority final priority for that for that
message once it receives these proposed priorities from all of the processes.
And this agreed priority is the maximum of all proposed priorities and it's sent back to
all the processes.
And when a process receives this agreed upon the final priority for a message M, it updates
this message M's priority and accordingly it reorders the message in the priority queue and it marks
this message M's deliverable and it then ends up delivering any messages that are at the front
of the priority queue, ok.
So, let me just dive into an example and this will probably become clearer and then I can
come back to the slide and if you have any questions we can tackle those, ok.
So, let us let us start with this example.
So, I have these three processes P 1, P 2, P 3.
So, suppose P 1 issues a multicast of let us say this message A, ok.
So, the first step is that P 1 itself will propose a priority for A, right.
So, this prior, so let us say that there were no other multicast messages issued before.
So, it starts with priority 1.
So, that is the highest so far, ok.
So, now let us say B's multicast message reaches P 2.
So, what will P 2 do?
No.
No.
This is not reliable multicast.
We are just, we are just doing basic multicast but we are now trying to implement the ICES
algorithm for ensuring total reliability.
Oops.
Ok, my, ok.
I thought I had removed all this automated timing from these animations.
There are lots of animations in these slides which are hard to debug and the other problem
is I cannot do back, ok.
What will P 2 do?
Yeah.
I will propose sequence number 1.
So, P 2 will see that hey you know I have not proposed any other priorities.
So, I will let me start with like you know the small smallest priority 1, it is smallest
is 1 and not 0.
It could be the things, ok.
So, P 2 will propose a priority 1 for this message B and it will send that proposal back
to P 3, ok.
So, P 3 has received this proposed priority from P 2, but it is still waiting on receiving
the proposed priority from P 1.
So, you agree upon a final priority value only after you have received the proposed priority
from all three processes, right.
So, P 3 basically knows that, ok, P 3 and P 2 have both proposed priority 1 for this message
B, but P 1's proposal is still left, ok.
So, we cannot proceed with delivering B anywhere.
So, B is still undeliverable, ok.
Then when P 1's message A reaches P 2, what will P 2 do?
Yeah, reply back 2, right.
So, now P 2 will say that, ok, you know I have received the second multicast message
and I have already proposed a priority 1 for the message B. So, for this second message
that I have, I am receiving, let me propose a priority 2.
So, remember the proposed priority that, the priority that you propose for a message is
always higher than your previously proposed values, ok.
Alright.
So, now basically now this message is then sent back to P 1.
And now let's suppose P 1's message reaches P 3.
So, P 3 will also propose a, ah, ok.
So, it's hard to debug these animations when I am like walking over the slides on my own
because I, like the timings are always different.
Anyways.
So, P 3 will also propose a priority 2 because P 3 has proposed priority 1 for message B.
So, P 3 will also propose a priority 2 for this message A and it will send back a response
to P 1, ok.
But before that response reaches P 1, let's say P 2 ends up issuing another multicast C, ok.
So, now P 2 will end up proposing a priority 3 for this multicast C because it has already
proposed priority 1 for B and it has proposed priority 2 for A. So, the next higher value
is 3.
So, P 2 will propose priority 3 for this multicast C. And, ah, and this message reaches P 1.
So, what will P 1 now propose for C? 2, right.
So, P 1 has proposed 1 for A. So, it will propose the next higher value 2 for C. And, what will
P 3 propose for C? 3, right.

.
So, P 3 has, has seen priorities 1 and 2 before.
It has proposed priorities 1 and 2 before.
So, it will propose 3 for C, alright.
So, now P1's proposal for C has reached P 2.
P 2 will still not do anything little with sitting on P 3's proposed, proposed value,
ok.
So, now finally P3's message B reaches P1.
What will P1 propose as B's priority, 3, good, okay, all right.
And then A's proposed priority 2 by P3, so P3 had proposed priority 2 for A, so that
proposal reaches P1.
So, now what will happen?
So, now we see that at P1 we have the proposed priority for A from all 3 messages.
So, we have the proposed priority of 1 from P1, proposed priority of 2 from P2 and proposed
priority of 2 from P3, okay.
So, now P1 is ready to figure out what should be the final priority of A. So, what will it
pick as the final priority of A?
2, right.
It will take the max of all of these proposed values and it will pick 2 to be the final priority
of A, okay.
And then it will update this priority value to 2.
And it will mark this A as deliverable.
So, this color change indicates if a non-gray color here indicates that it is deliverable.
But there's a problem now, right.
So, we now need to sort these messages by the order of the priority.
And we now see two messages in in P1's queue, which both of which have priority 2.
So, how do we go about it?
Can you just like deliver any of them in any order?
Let's assume like C is C is not deliverable yet, but suppose C became deliverable with
a priority 2.
So, could we have delivered it in that order, in any random order across processes?
It, the third priority value could, could end up.
Once it becomes deliverable, could both end up with two, ah.
Yeah.
Actually, it's a good question.
I need to think a little bit more about it.
Maybe, maybe it won't.
But we still need a way to, to even, even locally, like even at this time instance, like
whether A, whether A can be delivered or not.
Because we don't know whether, actually yeah, so C, in this case C's priority will end
up being higher, but if A is currently deliverable, I'll actually have to have to think a little
bit more about it and get back.
Like if, if we can actually prove that eventually like they will end up being, being different.
But there, there is a, that's the key though, like you know there is, there is like a reason
why they might like end up being different and we can use that to even at this point like
order these messages.
So, I think, okay let me, let me, let me, let me, let me, let me, let me, so in, in this
particular case, yes C's priority will end up eventually being different and it might
have been safe to deliver A maybe, actually no, yeah, yeah, it might have been safe to
deliver A, but, oh, okay my microphone, yeah, okay, but there could be other cases where
like let's say A2 is still the proposed priority, like A2 and C2 are still the proposed priority,
we might still want to order them in some way at, at our queue.
So how do we do that?
And we can leverage the fact that there is some process which will, which will be able
to distinguish between, between the priorities.
So the, the way we do that is that we break ties using the, using the, the process ID of the,
using the ID of the process that has suggested that, that highest priority value.
Okay?
So, you see whenever we implement a priority queue like we, we, we need unique priorities.
So, if you have a priority queue and you have the same priority and you end up like sort
of ordering them in a random order like sort of safe, safe safety could be violated like
you might end up breaking total order.
I do need to actually think about whether after the final priorities are decided like could
you, could that ever happen if we don't end up breaking ties.
So the way, the way we, we do that like just as like, you know, an added like safety sort
of cautious mechanism conservative, conservatively is that the process number, the, the process,
the ID of the process that has suggested the, the priority is appended to this priority value.
Okay?
So here three dot two means that process two has proposed priority three for that, for that
message.
And no, no the dot here is not a decimal point.
Like people get confused that this is like a decimal point.
No, no, no.
So the way to compare that is that you first look at the, at, oops.
You first look at the priority value.
If the priority value is higher then that message should come, basically this 2.1 should
come after 1.3 in the priority queue.
But if the, if the priority value is the same then you look at the process ID and you order
the, the, the messages based on that.
Okay?
So any questions on this?
Okay.
So now, so now what we do here is so, now if we come back to our example here.
So, so far we just have these, the, the, these, these proposals based on, based on the,
whichever, whichever, whichever process proposed the highest value we, that that process ID
has been appended to that, to that, to that priority that each process locally maintaining.
Then when P1 receives this proposed priority of 3 from, from P3, it will end up updating this
to 2.3.
It will mark it as deliverable.
But because 2.3 is higher than 2.1, it will order the, the messages in this manner.
Okay?
Right?
Because here like basically P1 at this point does not know whether other processes will end
up proposing a higher priority for C or not.
So, it, it may not be safe to deliver A, but maybe, maybe, maybe it would have been, I'm
to work out that proof.
You had a question?
Yeah.
You had a question?
Yeah.
Other process as in?
Yeah, we, so now the agreed, so this is just P1 setting the agreed priority value.
But now it will send it to these other processes.
So that was the next step in, in this.
Okay?
So now these other processes will receive this agreed upon value.
And they'll also update the, the priority to 2.3.
And they will adjust their, the position of, of A in their priority values.
Okay?
Yeah.
.
A has not gone from priority 2 to priority 3.
It's 2.3.
So it's still priority 2, right?
But it's saying that, okay, it's process P3 is the one that has proposed this priority,
highest priority 2.
So basically, okay, so if we look at this example.
So, so, so far we saw that, yeah, okay, it's, it's kind of, because there's so many animations,
it's hard to kind of track the particular thing.
But, okay, P1 had proposed priority 1 for A, but these P2 and P3 had proposed priority 2,
right?
So now basically P1 will say that, okay, the priorities I've received for A include one proposed
by me, 2 proposed by me, 2 proposed by P2 and 2 proposed by P3.
This is the highest amongst this, so I'll set 2.3, okay?
So basically append the ID of the process that has proposed that, that value, that priority
to that, to that, to be, to you said that, you attach that to the priority value basically,
and then you do that, okay, all right, so now, now, so now A is technically deliverable
at all of these processes, but we won't deliver it yet.
We can only deliver a message when it's at the head of the queue, okay?
And messages could be, like, reordered depending on what the final priorities end up doing.
Okay, so now P1, P1, P1's proposal for message B, so P1's proposal for message B reaches P3.
So, now P3 has all of the proposals for message B.
What will it set as the final priority for B?
3.1, right?
So, it will again pick the highest.
So, these are the three values it will compare, and it will pick 3.1 to be the final priority
of B, right?
And, and 2.3 is less than 3.1, so A and B will swap places in the priority queue.
And, now, we can see that both A and B are deliverable, okay?
So, the, the blue and the yellow color doesn't mean too much here, as long as it's not grey,
it's deliverable in these slides.
And, we, P3 will end up delivering both.
So, now, it's safe to deliver A and B in that order.
So, it will first deliver A and it will then deliver B, okay?
And, and P3 will also send out the agreed priority to other processes, but they have not yet
reached, so I have not yet drawn the arrows for those, okay?
Now, P3's proposal for C, C's priority reaches P2.
So, now, now P2 has also received all the proposals for C. What will be set, set as C's
final priority?
3.3, right?
So, oops, yeah.
So, P2 will set 3.3 to be C's priority.
And, yeah.
And, let's say this final priority reaches both P1 and P3 as well.
So, they'll also set 3.3 to be C's priority and we'll swap places again.
And, P3 can deliver C as well.
So, P3 had already delivered A and B. So, it can deliver C as well.
So, these check marks here indicate that.
And now, P1 can deliver, deliver A. So, A is deliverable.
It's at the head of the P1's queue.
So, it can deliver A.
Then, finally, once P3's when the final priority of B as decided by P3 reaches P2.
The final priority of B gets updated by P2 and you rearrange the priority queue and P2 can
now deliver all three messages in the order A, B, C. And, once B's priority, final priority
reaches P1, P1 will update B's value, priority value.
The priority queue remains unchanged in this case and B and C get delivered.
To the application.
Yeah, yeah, yeah.
So, all of this is happening.
Remember that diagram I used to have.
So, all of this is happening as part of the total order multicast protocol.
So, you basically have like you know the basic total order multicast implemented on top
of basic multicast, right.
So, these actions happen upon the B delivery.
But, the total order multicast protocol is the place where this priority queue is maintained.
We are buffering these messages.
And, this total order multicast protocol, that's just underneath your application,
will then deliver the message to the application once the conditions of the access
are satisfied.
At this point, so when, when, when I have the check mark here, that's when the message
is getting delivered to the application.
Yeah.
Oh, by these arrow endings.
So, the, the very first time it's basically, so the B delivery, okay, what are the, the basic,
so you can remember this diagram here, right.
So, you have your application, you have the total order multicast protocol and then you
have the basic multicast protocol, right.
So, the basic multicast protocol will just deliver the messages to the total order multicast
protocol as soon as the messages arrive at the process, right.
So, that's the, that's the, these arrows.
So, basically direct multicast of A is issued by P1, it gets B delivered at P2, it gets B delivered
at P3, but, yeah, it's still, it's still, it, then ends up getting buffered in this total
order multicast, by the total order multicast protocol in this priority queue.
So, the message is not delivered to the application yet.
Yeah, I said it's not related to the application.
So, when you are doing this,
right, and then it's not to be active,
and then it's not to be active,
and then it's not to be active,
and then it's not to be active,
and then it's not to be active,
how is it reliable?
How is it reliable?
We're not talking about reliability,
we're talking about total ordering here.
We're not talking about total order reliable multicast,
we're just talking about total order multicast, right.
So, we, we are implementing total order multicast over basic delivery.
Now, total order reliable multicast is whole other thing, right,
and that's what you're supposed to do for your MP1.
I'm not going to tell you how exactly you'll do that,
you have to think it through, okay.
So, I'm not guaranteeing reliability here.
So, I'm not even going into what will happen when,
when failures occur.
I would like you all to think about it,
and we can, we can discuss that,
maybe after the MP1 is due.
Okay, and that's, that's the part of like,
how you think, think things through, okay.
Yeah.
.
Yes.
.
Right.
.
Yeah.
.
Right.
.
.
Now, so actually, just to continue on the note of reliability.
So, now if you want to ensure reliability on top of this total order,
multicast delivery, you need to make sure, I mean,
like you need to kind of, this is like what the focus
need to do for MP1.
So, you need to make sure that if one process has delivered the message,
basically this, this thing has happened, like, you know,
you have a check marks here, it's at the head of the ISIS priority queue,
and you've delivered it.
If one process has delivered it,
all other process must deliver it as well.
So, think about how, how you would like augment this ISIS protocol
with reliability, like what, what aspect here must use R multicast.
So, currently I've used B multicast everywhere,
but you can maybe use R multicast somewhere here to make sure that
reliability is guaranteed.
Okay.
All right.
Yeah.
.
What is the second part?
.
The final priority?
Yeah.
.
Yeah.
So, yes, so I mean, especially if you, like,
you can think about whether you need reliable multicast
in the first part.
You do need it for the final priority,
and I'll let you all, I'll leave it up to all to work out,
like, where you need R multicast.
Okay.
Yeah.
Okay.
Okay.
So, why, why does this, okay,
it's actually any questions on this algorithm.
Let me actually go back to this slide now,
now that we have looked at the example.
So, just stare at it for a bit.
If you have any questions, feel free to ask.
So, is the, is the process clear?
Can you repeat your question again a bit more coherently?
.
.
.
Right.
.
.


Yeah.
.
.
.
.
.

.


.





What is, what is the sequence one?
.
.
Why is, why does, so, B has priority 3.1,
it doesn't have sequence one.
So, the, the, so, here like we have replaced the terms.
So, you can think of this priority to be equal to the sequence.
Okay.
We are using the term sequence and priority interchangeably.
And, like, as, so, this is, this is a slide that you need to kind of look at again maybe.
So, you, you have the, the first number here is basically the sequence or the priority.
The second number here is the process ID that has proposed that sequence of priorities.
The ID of the process that has proposed that sequence of priority.
And, that is the tuple we use when comparing these sequences of priorities across messages.
Okay.
So, oops.
So, I am not understanding a question then.
So, given that do you still have a question?
.
.
.
.
.
.
So, so, what that means is that when P delivers M1, it is at the head of P's queue.
Because, it's only then that, that message will end up getting delivered.
And, if it is delivering M1 before M2, that means that M2 can have, can be in one of the
following places.
So, it's possible that M2 is already in, in P's queue and it is also deliverable.
But, it's not at the head.
So, the final priority of M1 is less than the final priority of M2.
So, here when I say less, remember that less means that like you know when we talk of priority,
less means that like it actually has higher priorities delivered first kind of a thing.
But, like the value is less.
Okay.
So, final priority of M1, the final sequence of M1 is less than the final sequence of the
final priority of M2.
The other condition could be that M2 is already in P's queue, but it's not yet deliverable.
So, that would mean that the final priority of M1 is, must be less than the proposed priority
of M2.
And as we know that the final priority that will be selected for M2 is guaranteed to be
greater than equal to the priority of M2 proposed by any, any of the processes.
So, therefore, final priority of M2 must be higher than the final priority of M1.
And therefore, the final priority of M2 is guaranteed to be higher than the final priority of M1.
Okay.
Are you all following this?
Any questions on these conditions?
Why?
Why this must be true?
.
So, by design, right.
So, the way I just works is that each process will send its proposed priority to the sender,
right.
And the sender by design is picking the max of all of the proposed priority and setting
that to be the final priority, right.
So, the final priority set as the max of all possible proposed priorities, then this is
second condition is guaranteed to be true, right.
Okay.
All right.
So, similarly, if now let's assume the contradiction that, you know, let's say P prime ends up delivering
M2 before M1, by a same set of arguments, the final priority of M2 will end up being less
than the final priority of M1.
But that's a contradiction because we can only have one final priority for each message.
So, we can't have that at two different processes.
So, basically, so, this is not possible.
So, by, well, so, using this group by contradiction, we can say that if M, if M is, M1 is delivered
before M2 at, at process P, it must be delivered in the same order at process P prime as well.
Okay.
Is this clear to everyone?
Any questions?
All right.
All right, okay.
So, this is clear, I will move on to the next multicast ordering flavor which is causal multicast.
So basically how to implement causal matricast, okay?
Really, any questions on ISIS?
Yeah.
Right, max of all the proposed ones.
Yeah.
But here like when we are thinking of, so now once you kind of incorporate that as part
of your algorithm, right?
So now this how we are concatenating things also basically this whole tuple becomes part
of the priority.
So that max that we are considering is taking that tuple into account, entire tuple into
account.
And that's why I couldn't directly answer your question given I knew the answer that we were
breaking tie in this manner.
I hadn't thought about like, oh, if I don't break ties, like, I'm actually not sure.
That's why I didn't want to answer in either direction about whether that will necessarily
be true.
It might, it might be true, but we have to work out the proof.
There could be cases where it actually ends up not being true.
Right, but yeah, I think now when we think of max like remember like, oh, where is my scribbling?

So like the way we are picking the max is taking that whole tuple into account.
So when, when A set, set like 2.3, sorry, when, when P1 set 2.3 to be A's final priority,
it didn't set 2.2 for that reason.
2.3 is higher than 2.2.
So even though both P2 and P3 propose the priority 2 for A, 2.3 was selected as the final
winning tuple as the priority 4 for A. All right.
Any other questions on ICES?
Yeah, given the amount of questions I usually get, I was expecting more questions on ICES.
So that's why I'm reluctant to move on.
So really, I'll move on, okay, I'll move on then, okay.
So coming to the implementation of causal order multicast, so just a quick reminder, so
what causal order means is that if multicast of M was issued before the multicast of message
M prime, then any correct processor delivers M prime should have already delivered M, okay.
And as, as we discussed extensively in the last class, here the happen before relationship
is governed by Lampot's happen before relationship, but the key thing is that we consider the messages
that are delivered at the process, like the, the, the, the causality is established by the,
by the delivery of messages and not just by the underlying protocol receiving the messages,
ok.
All right.
So, how do we go about implementing a causal order multicast?
So, the idea is similar to how we implemented the FIFO order multicast, so each process is
maintaining some kind of a sequence which is sent along with the, with the message.
But what we sent with the message differs instead of sending this is one sequence value end up
by sending a sequence vector and the updating rules also differ, ok.
So, in particular each process, each receiver maintains a vector of per sender sequence numbers
or integers.
So, if a process is P 1 through P n, P i maintains a vector of sequence numbers 1 to n initialized
as, as all zeros and P i j is the latest sequence number P i has received from P j, ok.
And it ignores other, and it ignores other network messages and only looks at the multicast
message delivered to the application.
So, the, the, the, the causal order is established only in the context of these multicast messages.
So, when a process P j issues a message, the multicast of a message m, it will first increment
this, the, the jth index of this vector that corresponds to its cell and it will send this
entire vector 1 to n with m as its, with, along with m as the sequence vector, the sequence
number corresponding to m, ok.
And then when, when a, when this message is B delivered at, at another process P i, remember
like again we are implementing a causal order multicast protocol on top of like a basic multicast.
So, when this message is B delivered at, at P i and let us say this, the, the, the, the
message has, has a sequence vector B.
So, now P j will end up, sorry P i will end up buffering this message until two conditions
are satisfied.
The first condition is that this is, this message is indeed the next message that P i was expecting
from P j. And, and all, for all k not equal to j, B k must be less than, so all, all multicast,
anywhere in the group which happened before m must have also been received by P i, ok.
And when the above two conditions are satisfied then we can, ah, deliver, ah, ah, we, ah, this,
this message M. So, ah, I'll, I'll come back to the slide, let me go over an example and this
might become clearer, ok. So, basically what, what these vectors are representing and, and
why, why we have these conditions, ok. So, ah, let's consider this, ah, ah, ah, ah, these,
these three multicasts issued at these three processes. So, the sequence vector we initialize
that as 0, 0, 0, 0, 0 at each of these four processes, ok. Then, when P 1 issues its multicast,
this is the thread multicast, ah, it will update its sequence vector. So, what, what will it
update it to? 1, 0, 0, 0, ok. So, it is, this is just saying that, ok. So, by the self-deliveries
are omitted for simplicity. But, yeah, once it issues this multicast and it self-deliveres
it at the same time, it will basically update the sequence vector to be 1, 0, 0, 0, ok.
So, this indicates that this is the first multicast from P 1. Now, this 1, 0, 0, 0 is, ah, is piggybacked
along with the message and it's sent to all the, all the processes, ok. So, now when P 4 receives
this, ah, this message 1, 0, 0, 0, 0, it will see that, ok. My, my current, ah, my current
sequence at, at this first index was 0. I received this message 1, 0, 0, 0, I was expecting 1 from
P 1 and all of the other, ah, all of the other indices are the same, they are all like 0, 0,
0, 0, 0, 0. So, both of these conditions get satisfied and this message can be delivered,
ok. So, it is the next message I was expecting from P 1 and everything else is the same, ok.
So, P 4 will end up delivering this message, ok. Ah, what about P 2, will P 2 end up delivering
the same, ok. Yeah.
So, if you think for the conditions again, yeah.
Yeah.
So, the first one is this message is the next one P, I, so that, that means that that's
the one, here, here, here, here, so, right. Yeah. And what if the.
And what if the.
The one, the, the first index is one and it goes from.

So, here basically, ah, ah, ah, ah, for all of the other indices, the, ah, the values in
and that vector that you're getting from the message
should be less than equal to the, to what?
The one that we just updated?
Yeah, yeah.
Wait, did I have it wrong here?
Do I have it the other, no, no, no.
Wait, actually just let me just double check.
I might be blanking out here a little bit.
I had that value wrong in my slide.
Wait, just one sec.
Yeah, no, I have it right here.
Sorry, I got a little bit confused in the directionality.
Okay.
All right.
Okay.
So, you end up delivering it at, at, at P 4.
What about P 2 will end up delivering it at P 2?
Yeah.
So, same, same condition you end up delivering it.
Okay.
Okay.
Then, at P 3 this red message reaches quite late.
So, let's see what, what, what, what will P 2 do when it issues the multicast of the blue
message?
Yeah.
So, P 2 will change.
So, once it, once it delivers this message, the sequence vector at P 2 has become 1 0 0 0.
So, it will be, so when, when P 2 issues the blue multicast, the sequence vector gets updated
to 1 1 0 0 0.
Okay.
So, what, what this indicates at this point of time is that P 2 has delivered one message
from P 1.
So, that's what the first index indicates.
And it indicates that, okay, now P 2 has, so P 2 has delivered one message from P 1.
And now P 2 is issuing its first multicast, okay.
So, that's what this 1 1 0 0 indicates.
And it has not yet heard from P 3 and P 4.
Not, not yet delivered any messages from P 3 and P 4, okay.
So, next when, sorry, okay.
So now when P 2's message reaches P 1, will P 1 deliver it?
Yes.
Yes.
And what will the updated sequence vector at P 1 be?
Yeah.
So, it will be set to the piggyback vector, which, and it will be basically 1 1 0 0.
So, more than setting it as a, as a, as a piggyback vector, the, the, the, the, what the algorithm
will do is it will update the, the second index, incremented by one.
Which is, which ends up being the same as the piggyback value.
It may not always, may not always be the case maybe.
Yeah.
Yeah.
Okay.
So, now what this indicates is that P 1 has, has issued one multicast, self-delivered it
as well.
So, that's what the first index indicates.
And the second index indicates that P, P 1 has now delivered a message from, from P 2.
Okay.

Now, P 3 receives this blue message next.
Will P 3 end up delivering the blue message?
Hmm?
Yes.
Or no.
Okay.
So, let's, let's come back to our condition.
So, now, now P 3 is, P 3 is stuck at 0 0 0 0.
Right?
And it receives a multicast with sequence vector 1 1 0 0.
So, if we come back and look at these conditions here.
Is the second condition satisfied?
No?
Right.
So, the second condition is not satisfied.
Are you all following?
Okay.
Okay.
So, the second condition is not satisfied.
So, basically what it indicates is that it's, it's missing a one from, from P 2.
So, P, basically the, this blue, this blue multicast when it was issued.
So, this is basically what's helping it establish the causal order.
So, what it indicates is this blue multicast when it was issued, P 2 had already delivered
a message from P 1 and P 3 has not yet delivered that first message from P 1.
So, P 3 should hold on to this blue multicast and buffer it until, until that condition is
satisfied.
Okay?
So, so this vector here, the first index of this vector is greater than the first index
that P 3 maintains and so the, the second condition is not satisfied.
Okay.
All right.
Is this clear?
Yeah.
.
Yeah, yeah, yeah.
Remember the, this is the rules that we discussed in the last class on Friday, right?
Is this clear?
Yeah.
It's, it's, it's based on the, so here the delivery actually happens, right?
So, the delivery has happened and then blue has, so even the application has seen the red
multicast before it issued the blue multicast.
.
Yes.
Not just receiving, it's a delivery, it's a delivery that establishes causality, yeah.
So, so the reason that we cannot deliver for this one is because, um, the, the second entry
is one and not zero?
So, it's because the first entry is one and not zero.
So, this is the second entry is so, with respect to the second entry, so there are these two
conditions here, right?
So, let's look at this.
So, basically you are receiving this multicast with vector one, one, zero, zero and this process
is, is basically at zero, zero, zero, zero.
So, now the first condition is satisfied, right?
So, if I look, if I compare the second index, I am, I am receiving it from P 2, right?
So, if I look at the second index, I am actually expecting sequence one from P 2.
.
Yeah, so this, this condition is satisfied, right?
But this condition which is saying that, okay, I have received this vector and for all
values that are not equal to two, basically in this case two, right?
So, for all values that are not, do not correspond to the index of the sender, the, the, the values
at, at this, the value in the vector should be less than or equal to basically the, the
values that I currently have.
So, I should be at least as up to date.
So, in that case, isn't it impossible to deliver any messages that have more than, that
don't have, you know, zeros?
So, we have to update, you know how it says zero, zero, zero, zero, right?
Can we have to update that?
No, it's less than or equal to, right?
We did end up delivering, sorry.
We did end up delivering these two messages.
Yeah.
Yeah, but once, once like the blue, so what this is, what this is essentially at the core
what it's saying is that when the blue multicast was issued P 2 had delivered one message from
P 1.
So, now all processes that deliver this blue multicast should also have delivered this one
one message from P 1, the first message from P 1.
Okay.
And that is what is establishing causality.
So, the way to check that is basically you put in the sequence counter of P 1 into the
vector.
This is what this is.
So, this is saying that, okay, one message from P 1 had been delivered.
And now all the processes that are receiving this blue message check that, hey, you know,
have I delivered a message from P 1?
If not, I should wait before I deliver this blue message.
Yeah.
Okay.
All right.
So, it's not, I didn't follow what you meant by no messages can be delivered because everything
is zero first because.
All the green ones are just all zeros.
Are those ever going to get updated?
Yeah.
This is the update, right?
This is the update.
Oh, yeah.
Yeah.
Yeah.
I mean you're updating that as and when you're sending the multicast and you are, you're
delivering the messages, you're updating that.
So, this is the last step, right?
Yeah.
Whenever you deliver a message, you update that.
So, this is, this was just a start thing.
Yeah.
Okay.
All right.
Any, any other questions?
This is, are all of you following?
Yeah.
Okay.
Yeah, just that like I, the faces are looking somewhat blanker today.
Okay.
Because there are a few questions coming from here and there, but I think some of you are
looking pretty blank.
So, I'm, I'm not getting enough, enough feedback.
Okay.
So, then when P4 issues the purple multicast, it will now increment this fourth index in the

Okay.
I have received this, the first index is here.
Okay.
I have received this red multicast from P1, sequence one.
And now this, the fourth index indicates that, okay.
I'm issuing my, my multicast.
Then this, this fourth multi, this P4's purple multicast reaches P1.
Will it get delivered here?
Yes.

Okay.
No, no issues.
The delivery happens.
Will it get delivered here at P2?
Yes.
It gets delivered.
Will it get delivered here at P3?
Hmm?
YS.
Does it satisfy both conditions?
Not the second condition.
Not the second condition still, right?
If this is P, P, so P3 is still stuck at 0, 0, 0, 0, right?
So, for the same reason that P3 ends up buffering the blue multicast, will end up buffering the
purple multicast as well, okay.
All right.
Yeah.
And then P4 receives the blue multicast.
Will it end up delivering the blue multicast?
Yes.
Okay.
So, notice that the, the last index here is different from the last index that is carried
by this blue multicast, but that's okay.
This value is higher.
So, you can, you can deliver it.
The second condition is still satisfied.
Okay.
So, it, it, it basically means that, basically the, the blue and the purple multicast are concurrent
and it means that, okay, for the blue multicast to be delivered, we should have delivered
this red message from P1, this first multicast from P1, that condition is satisfied.
So, blue can be delivered irrespective of what happens for the other indices afterwards,
okay.
Then the red, the red multicast hits P3, can, what, what happens at P3 now?
Can the red multicast be delivered?
Yes.
Okay.
So, what will, what will P3 do?
Once it delivers the red multicast, what will its sequence vector be?
One, zero, zero, zero.
One, zero, zero, okay.
So, like going, going back to the slide.
So, once you deliver a multicast, you update your sequence vector at that index only, okay.
So, you update your index vector at that index, you set the, that corresponding index to be
the same as the, what the, what the sequence vector carried by the messages at that index.
So, from, from Pj.
So, yeah.
So, yeah.

So, when, when this red multicast hits P3, so P3 will update its sequence vector to one,
zero, zero, zero.
Once it has updated sequence vector to one, zero, zero, zero, can it deliver the blue multicast?
Yes.
So, then both conditions for the blue multicast will be satisfied and at that point the blue
multicast from P2 can be delivered at P3.
And what about the purple one?
Can it also deliver the purple multicast?
Yes.

Okay.
So, once, once, once P3 delivers this red multicast, it updates its sequence vector to one, zero,
zero, zero.
And the causality conditions for both the buffered multicast get satisfied and it can end up
delivering both of them.
Okay.
Yeah.
.
If P3.

.
That would be fine too.
Yeah.
In fact, like this P4 is delivering purple before blue.
So, the self deliveries are happening right away and that's okay.
Yeah.
And yeah.
You had a question?
Yeah.
After we send the purple one out?
Yeah.
So, there is no, why would, so forget about how we are implementing this.
Like why would like blue not be delivered at P4 after the purple one?
Is there any reason?
.
Can you speak a bit louder?
Yeah.
.
.
Right.
.
So, P this is the reason why we are not delivering blue at P3 is because it was not
to receive the red multicast.
Okay.
And there is a clear causality between the red and the blue multicast.
So, the red multicast happens before the blue multicast because the red multicast is
delivered at P2 before the blue multicast is issued at P2.
and delivery and issuing of the red multicast
happens before the delivery of the red multicast.
So red multicast is issued before the blue multicast
is issued, so that causality is established.
Similarly, we have established a causality
between the red and the purple multicast, right?
So P four ends up delivering the red multicast
before it issues the purple multicast.
So the red multicast from P one happens
before the purple multicast from P four.
But we don't have any causality relationship
between the blue and the purple one,
and they can be delivered in either order.
So now, so what one question was why does P four
and what was the question, why does P four end up issued?
Why can we send P four before receiving what?
Why would we want to wait for the blue signal
before sending the purple one out?
Like when a process decides to issue a multicast
is its own wish, right?
Like, I mean causality is established based on, okay,
like I am issuing a multicast after some message
has been delivered to me.
That indicates a potential causality
and I should keep track of that.
That's what all we are doing, right?
I'm not like purposely trying to delay the issue
of a multicast that's ready to be sent out
because I want to establish a causality.
I don't want to establish causality,
I want to respect causality that gets established based
on how the multicast are issued.
So that's the key distinction, okay?
And in fact, with this causal order multicast,
if we're just implementing that,
like self-deliveries can also happen right away.
Self-deliveries happen right away and that's still correct.
When a delivery happens for other multicasts
is what's going to establish the causality.
Okay, so a process is free to issue a multicast
whenever it wants and self-deliver it,
but when it can deliver the multicast from other processes
is what's going to establish causality
and influence how it's going to, sorry,
basically the causality that gets established
will influence how it ends up delivering the messages
from other processes, all right, yeah.
Okay, cool.
.
Mm-hm.
.
You might need to, right?
So it's possible that like I, like there is,
let's say there's some, hypothetically there's some causality
between the blue and the purple message, right?
And let's say like, you know, so the blue should
be delivered before purple, hypothetically supposing.
And at P3 I ended up like first buffering purple
and then I ended up offering blue and then I delivered it.
So then I look at like, you know, my purple message first,
oh, I find out it's not deliverable.
But then I look at the blue message and I see that,
oh, causality condition is satisfied, I can deliver it now.
Then I might have to go back to the purple message
and check that, okay, now that I've delivered the blue message,
can I now deliver the purple message?
And then I can deliver that.
In this case, the two are concurrent,
so I could have delivered them in whatever order.
But yeah, you might need to kind of go back and check.
.
Yeah, you could do some kind of an ordering.
Yeah, so then you could be smarter about that, right?
So if you're just like, so it depends on how you're implemented.
That's an implementation detail, right?
So it depends on how you're implementing it.
If you're just implementing it by storing the messages
in the order in which they arrive,
you scan once, you may have to scan again.
If you end up storing them in some like causality order,
that okay, like I know that like, you know,
from the vectors of like blue and purple,
like I, there is a dependency between them.
If you end up storing them in that order,
you may, you might skip like a second scan.
So yeah, you can be smarter about how you implement.
I mean, but then you're paying the cost
during the insertion time.
So when you're inserting the message in the buffer,
you're doing some kind of a scan to figure out
what's the right place to insert it.
But yeah, so there's a trade off.
You had a question?
.
Yeah.
.
Yeah, so for delivery of red multicars
does not happen for whatever reason,
then what would, what that would mean is that at P2,
my sequence vector is still stuck at 0, 0, 0, 0, right?


Yeah, and then the blue multicars sequence vector
would look like 0, 1, 0, 0.
And then like there is no dependency of having
first receive the red multicars at other processes
and the blue one can then be delivered before the red one.
So the causality is not established between the red
and the blue multicars.
So yeah, so if you, and if you end up like buffering this
for whatever reason and delivering it after the blue one,
you, you don't end up establishing the causality.
.
.





.



.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.





.
.
.
.
.
.

.
.

.
.
.
.
.
.
.
along this tree, okay?
So this way, like once we construct this tree,
all processes will receive the message,
but we end up avoiding the redundancy, okay?
So yeah, so the basic idea then is that the process
will end up sending the message,
we need to a subset of processes in the group
that are, that has direct children in this tree.
So if we do such a thing,
again if we take a look at the physical network,
there might still be some redundancy,
like if this graph, if this like process level graph
is implemented like so, executed like so in the physical
network, there might still be some redundancy,
we may still end up sending some redundant packets
in the network router, but we can also possibly construct
a tree that includes the network router itself,
and this is, there's a protocol for it called IP multicast,
it's, it's very hard to deploy protocol,
like there's, there's been a lot of proposals
around IP multicast, people don't actually end up
deploying it, they mostly end up doing like
some kind of an overlay tree,
not involving all of the routers in the internet,
but the protocol is still out there,
it's just, it's hard to deploy,
it's just a side note, okay?
But yeah, so the basic idea here is that you can
construct this multicast tree,
and this tree based multicast will basically help you
in reducing some redundancy in how many packets
you're sending out when you're trying to do your multicast.
But the problem, one problem that arises could be that,
you know, if a node fails, then I have this overhead
of like, you know, reconstructing the tree to make sure
that all of the other nodes in my system
receive the multicast message.
And so one way to overcome that is through
this approach called gossip.
So in gossip, each, each process ends up
transmitting the message to B random targets.
Okay, so you just randomly pick like B other processes
to send the message to, and you just send the message
to those processes.
And other nodes do the same when they receive the message.
So yeah, everyone just randomly picks like B neighbors
they know about and send the message to those, and so on.
So there is no tree construction overhead,
and it's more efficient in terms of how many packets
you end up sending out into your network,
compared to unicasting it to just all possible receivers.
And this is also known as epidemic multicast.
Can someone tell me why?
Like an epidemic, right?
So in fact, this value B, like how many nodes you send to,
it's also like one of the spreading factor for epidemics as well.
So if this value is more than two, then the epidemic can spread very widely.
I'm forgetting the, there was some, for COVID that there was this value
which was like I think close to two or greater than two.
I'm forgetting the exact value.
But yeah, so it's kind of, it spreads like an epidemic.
So it's probabilistic in nature, there are no hard guarantees
on whether all processes will end up receiving that multicast message,
but it's good enough for many applications.
So it's, it's, it's somewhat probabilistic.
And it's actually used in many real world systems.
So Facebook distributed data store that will be
starting towards the end of this course.
So, uh, use this epidemic multicast as gossip for group membership
and Bitcoin uses it to exchange transaction information between.
And that concludes our discussion for multicast.
Thank you for staying one minute longer.
And yeah, I just wanted to wrap that up before
and then we can do a clean start on mutual exclusion on Friday.
All right.
Thank you all.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.

Thank you.
Thank you.





It's all about reporting.
So you decided you did not offer proof of any and the need

And if you have, I consider you something really
inache.
Yeah.

Thank you.
So for everyone appreciate you tonight's,

